{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-dt-0",
   "metadata": {},
   "source": [
    "# Learning Decision Trees by Inventing Them\n",
    "\n",
    "**Philosophy:** You won't be taught — you will *discover*. Every step builds on the last. Trust the process.\n",
    "\n",
    "---\n",
    "\n",
    "## What you'll need\n",
    "\n",
    "```python\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "Run the setup cell below before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 1: What Is Impurity?\n",
    "\n",
    "## Exercise 1.1 — Think About Mixing\n",
    "\n",
    "Imagine a bag of coloured balls — some **Red**, some **Black**.\n",
    "\n",
    "We want a number that captures how **mixed** the bag is:\n",
    "- A bag of **all Red** → not mixed at all → impurity = **0**\n",
    "- A bag of **all Black** → not mixed at all → impurity = **0**\n",
    "- A bag of **half Red, half Black** → maximally mixed → impurity = **1**\n",
    "\n",
    "Wait, that's backwards from what you might expect. Re-read the examples below:\n",
    "\n",
    "```\n",
    "impurity(0.5, 0.5)  →  1       # maximally mixed: impurity is 1 \n",
    "impurity(0, 1)      →  0      # all one colour:  impurity is 0\n",
    "impurity(1, 0)      →  0\n",
    "```\n",
    "\n",
    "> **Important:** Here **impurity = 0** means *completely pure* (easy to classify), and **impurity = 1** means *maximally mixed* (hard to classify). The naming feels backwards — but stick with it.\n",
    "\n",
    "**Before coding, answer these questions in the markdown cell below:**\n",
    "\n",
    "1. If a bag has 80% Red and 20% Black, would its impurity be closer to 0 or 1? Why?\n",
    "2. What is `impurity(0.9, 0.1)`? Higher or lower than `impurity(0.8, 0.2)`?\n",
    "3. What mathematical property must the function `impurity(p, q)` have when `p = 1 - q`?\n",
    "4. Is `impurity(p, q)` the same as `impurity(q, p)`? Why should it be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-3",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n",
    "4. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-4",
   "metadata": {},
   "source": [
    "## Exercise 1.2 — Invent the Formula\n",
    "\n",
    "We're going to invent the formula for `impurity(p, q)` where:\n",
    "- `p` = fraction of Red balls (between 0 and 1)\n",
    "- `q` = fraction of Black balls (between 0 and 1)\n",
    "- `p + q = 1` always\n",
    "\n",
    "**Step-by-step discovery:**\n",
    "\n",
    "**Step A:** Consider the function $f(p) = p \\times (1 - p)$. Fill in the table below by computing it:\n",
    "\n",
    "| p   | 1-p | p × (1-p) |\n",
    "|-----|-----|----------|\n",
    "| 0.0 | 1.0 | ?        |\n",
    "| 0.2 |     | ?        |\n",
    "| 0.4 |     | ?        |\n",
    "| 0.5 |     | ?        |\n",
    "| 0.6 |     | ?        |\n",
    "| 0.8 |     | ?        |\n",
    "| 1.0 |     | ?        |\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Compute the table values in Python and print them.\n",
    "2. What is the **maximum** value of $p \\times (1 - p)$? At what `p` does it occur?\n",
    "3. What are the **minimum** values? When do they occur?\n",
    "4. Plot $f(p) = p \\times (1 - p)$ for $p \\in [0, 1]$ using the helper below.\n",
    "5. Does this function behave like our desired impurity? Where are its max and min?\n",
    "\n",
    "**Plotting helper:**\n",
    "```python\n",
    "def plot_impurity_candidate(f, title=\"Candidate impurity function\"):\n",
    "    ps = [i/100 for i in range(101)]\n",
    "    vals = [f(p) for p in ps]\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(ps, vals, 'b-', linewidth=2)\n",
    "    plt.xlabel('p (fraction of Red)')\n",
    "    plt.ylabel('impurity')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HELPER — run this cell as-is\n",
    "def plot_impurity_candidate(f, title=\"Candidate impurity function\"):\n",
    "    ps = [i/100 for i in range(101)]\n",
    "    vals = [f(p) for p in ps]\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(ps, vals, 'b-', linewidth=2)\n",
    "    plt.xlabel('p (fraction of Red)')\n",
    "    plt.ylabel('value')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Step 1: Print the table\n",
    "print(f\"{'p':<6} {'1-p':<6} {'p*(1-p)':<10}\")\n",
    "print(\"-\" * 24)\n",
    "for p in [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]:\n",
    "    pass  # fill in\n",
    "\n",
    "# Step 2: Plot it\n",
    "# plot_impurity_candidate(lambda p: p * (1 - p), title=\"f(p) = p * (1-p)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-7",
   "metadata": {},
   "source": [
    "## Exercise 1.3 — Scale It\n",
    "\n",
    "From Exercise 1.2, you found that $f(p) = p \\times (1-p)$ peaks at $p = 0.5$ with a value of $0.25$.\n",
    "\n",
    "But we want `impurity(0.5, 0.5) = 1` (max impurity = 1, not 0.25).\n",
    "\n",
    "Wait — let's re-read the spec:\n",
    "\n",
    "```\n",
    "impurity(0.5, 0.5) → 1    ← pure (hard to classify = 1 certainty)\n",
    "impurity(0, 1)     → 0    ← certain\n",
    "impurity(1, 0)     → 0    ← certain\n",
    "```\n",
    "\n",
    "> Recall: **impurity = 1** means *maximally mixed/uncertain*, and **impurity = 0** means *completely pure/certain*.\n",
    "\n",
    "So we actually want a function that:\n",
    "- Returns **1** when `p = 0.5` (most uncertain)\n",
    "- Returns **0** when `p = 0` or `p = 1` (most certain)\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Take $f(p) = p \\times (1 - p)$ and apply a simple transformation to it so that:\n",
    "- Its maximum (at p=0.5) becomes 1\n",
    "- Its minimum (at p=0 or p=1) becomes 0\n",
    "\n",
    "\n",
    "1. Find the transformation mathematically (algebra only, no code yet).\n",
    "2. Write the resulting formula.\n",
    "3. Verify by plugging in: $p = 0.5$, $p = 0$, $p = 1$.\n",
    "4. Write it in Python and plot it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-8",
   "metadata": {},
   "source": [
    "**Your derivation:**\n",
    "\n",
    "- Maximum of f(p) = p*(1-p) is ... at p = ...\n",
    "- Transformation: ...\n",
    "- Final formula: `impurity(p) = ...`\n",
    "- Check p=0.5: ...\n",
    "- Check p=0: ...\n",
    "- Check p=1: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def impurity(p, q):\n",
    "    \"\"\"\n",
    "    Returns the impurity of a set with fraction p of Red and q of Black.\n",
    "    impurity(0.5, 0.5) should return 1  (most mixed = least certain)\n",
    "    impurity(1, 0)     should return 0  (all same  = most certain)\n",
    "    impurity(0, 1)     should return 0\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "# Verify the spec:\n",
    "print(impurity(0.5, 0.5))  # should be 1\n",
    "print(impurity(0, 1))      # should be 0\n",
    "print(impurity(1, 0))      # should be 0\n",
    "print(impurity(0.8, 0.2))  # should be between 0 and 1\n",
    "\n",
    "# Verify ordering:\n",
    "print(impurity(0.8, 0.2) < impurity(0.7, 0.3))  # should be True\n",
    "print(impurity(0.7, 0.3) < impurity(0.6, 0.4))  # should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your impurity function\n",
    "plot_impurity_candidate(lambda p: impurity(p, 1 - p), title=\"My impurity function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-11",
   "metadata": {},
   "source": [
    "## Exercise 1.4 — Explore the Function\n",
    "\n",
    "Now that you have `impurity(p, q)`, explore it.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Compute and print the impurity for the following bags. Do the results match your intuition?\n",
    "\n",
    "| Bag | Contents         | p     | q     |\n",
    "|-----|-----------------|-------|-------|\n",
    "| A   | 9 Red, 1 Black  | 0.9   | 0.1   |\n",
    "| B   | 7 Red, 3 Black  | 0.7   | 0.3   |\n",
    "| C   | 6 Red, 4 Black  | 0.6   | 0.4   |\n",
    "| D   | 5 Red, 5 Black  | 0.5   | 0.5   |\n",
    "| E   | 3 Red, 7 Black  | 0.3   | 0.7   |\n",
    "| F   | 10 Red, 0 Black | 1.0   | 0.0   |\n",
    "\n",
    "2. Is bag A more or less certain than bag B? Does `impurity` agree?\n",
    "3. Is `impurity(0.3, 0.7)` equal to `impurity(0.7, 0.3)`? Why should it be?\n",
    "4. What is the impurity of a bag with 50 Red, 50 Black, and 50 Green (3 classes)? \n",
    "   - Hint: Can you extend your formula? Think about what $p \\times (1-p)$ means for each pair of classes.\n",
    "   - (This is a bonus — don't worry if you can't figure it out now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "bags = [\n",
    "    (\"A\", 0.9, 0.1),\n",
    "    (\"B\", 0.7, 0.3),\n",
    "    (\"C\", 0.6, 0.4),\n",
    "    (\"D\", 0.5, 0.5),\n",
    "    (\"E\", 0.3, 0.7),\n",
    "    (\"F\", 1.0, 0.0),\n",
    "]\n",
    "\n",
    "print(f\"{'Bag':<5} {'p':<6} {'q':<6} {'impurity':>10}\")\n",
    "print(\"-\" * 30)\n",
    "for name, p, q in bags:\n",
    "    imp = impurity(p, q)\n",
    "    print(f\"{name:<5} {p:<6.1f} {q:<6.1f} {imp:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 2: Impurity of a List\n",
    "\n",
    "## Exercise 2.1 — From Fractions to Lists\n",
    "\n",
    "So far, `impurity(p, q)` takes fractions directly. But in practice, you have a **list** like:\n",
    "\n",
    "```python\n",
    "[\"R\", \"B\", \"B\", \"R\", \"R\"]\n",
    "```\n",
    "\n",
    "You need to compute `p` and `q` from the list yourself.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. For the list `[\"R\", \"B\", \"B\", \"R\", \"R\"]`, manually compute:\n",
    "   - Count of \"R\"\n",
    "   - Count of \"B\"\n",
    "   - Total count\n",
    "   - `p` (fraction of R)\n",
    "   - `q` (fraction of B)\n",
    "\n",
    "2. Write a function `list_impurity(items)` that:\n",
    "   - Takes a list of \"R\" and \"B\" strings\n",
    "   - Computes `p` and `q`\n",
    "   - Returns `impurity(p, q)`\n",
    "   - **Edge case:** What should it return for an empty list `[]`? Decide and document your choice.\n",
    "\n",
    "3. Test your function:\n",
    "   ```python\n",
    "   list_impurity([\"R\", \"B\", \"B\", \"R\", \"R\"])   # what do you expect?\n",
    "   list_impurity([\"R\", \"R\", \"R\", \"R\"])         # all same → what value?\n",
    "   list_impurity([\"B\", \"B\", \"B\", \"B\"])         # all same → what value?\n",
    "   list_impurity([\"R\", \"B\"])                   # exactly half → what value?\n",
    "   list_impurity([])                           # empty → your decision\n",
    "   ```\n",
    "\n",
    "4. Try these additional lists and rank them by impurity (most mixed to least mixed):\n",
    "   ```python\n",
    "   list_A = [\"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"B\", \"B\"]\n",
    "   list_B = [\"R\", \"R\", \"R\", \"R\", \"R\", \"B\", \"B\", \"B\", \"B\", \"B\"]\n",
    "   list_C = [\"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"B\", \"B\", \"B\"]\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def list_impurity(items):\n",
    "    \"\"\"\n",
    "    Computes the impurity of a list of \"R\" and \"B\" elements.\n",
    "    Returns a value between 0 (pure/certain) and 1 (maximally mixed).\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    [\"R\", \"B\", \"B\", \"R\", \"R\"],\n",
    "    [\"R\", \"R\", \"R\", \"R\"],\n",
    "    [\"B\", \"B\", \"B\", \"B\"],\n",
    "    [\"R\", \"B\"],\n",
    "    [],\n",
    "]\n",
    "\n",
    "for lst in test_cases:\n",
    "    print(f\"{str(lst):<40}  impurity = {list_impurity(lst):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking exercise\n",
    "list_A = [\"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"B\", \"B\"]\n",
    "list_B = [\"R\", \"R\", \"R\", \"R\", \"R\", \"B\", \"B\", \"B\", \"B\", \"B\"]\n",
    "list_C = [\"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"B\", \"B\", \"B\"]\n",
    "\n",
    "for name, lst in [(\"A\", list_A), (\"B\", list_B), (\"C\", list_C)]:\n",
    "    print(f\"List {name}: impurity = {list_impurity(lst):.4f}\")\n",
    "\n",
    "# Which is most mixed? Least mixed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-16",
   "metadata": {},
   "source": [
    "## Exercise 2.2 — Weighted Impurity of Two Groups\n",
    "\n",
    "When we split a list into two parts, we get two separate impurity values — one for each part.\n",
    "\n",
    "But how do we combine them into one number?\n",
    "\n",
    "**Think about it:** If one group has 100 items and another has 2 items, should they count equally?\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Invent a formula for the **total impurity** of two groups, `left` and `right`, that accounts for their sizes.\n",
    "   - What should happen if one group is empty?\n",
    "   - What should happen if both groups are identical?\n",
    "   - Hint: think about weighted average.\n",
    "\n",
    "2. Write a function `total_impurity(left, right)` that takes two lists and returns a single number.\n",
    "\n",
    "3. Test it:\n",
    "   ```python\n",
    "   total_impurity([\"R\", \"R\", \"R\"], [\"B\", \"B\", \"B\"])  # perfectly separated\n",
    "   total_impurity([\"R\", \"B\", \"R\"], [\"B\", \"R\", \"B\"])  # each group is mixed\n",
    "   total_impurity([\"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"R\", \"B\"], [\"B\"])  # unequal sizes\n",
    "   ```\n",
    "\n",
    "4. Reflection: For the last test case, the right group has 1 item (`[\"B\"]`) so it's pure (impurity = 0). But it only has 1 item out of 11 total. Does your formula give it less weight? It should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def total_impurity(left, right):\n",
    "    \"\"\"\n",
    "    Returns the weighted total impurity of two groups.\n",
    "    Each group's impurity is weighted by its size relative to the combined total.\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "# Test cases\n",
    "print(total_impurity([\"R\", \"R\", \"R\"], [\"B\", \"B\", \"B\"]))  # perfectly separated → expect high certainty\n",
    "print(total_impurity([\"R\", \"B\", \"R\"], [\"B\", \"R\", \"B\"]))  # both mixed\n",
    "print(total_impurity([\"R\"]*9 + [\"B\"], [\"B\"]))            # unequal sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 3: Finding the Best Split\n",
    "\n",
    "## Exercise 3.1 — Splitting a List at a Position\n",
    "\n",
    "You are given an ordered list:\n",
    "\n",
    "```python\n",
    "items = [\"R\", \"B\", \"B\", \"R\", \"R\"]\n",
    "```\n",
    "\n",
    "You can **split** it at position `k` (0-indexed), meaning:\n",
    "- **Left part:** `items[:k]` — the first `k` items\n",
    "- **Right part:** `items[k:]` — the remaining items\n",
    "\n",
    "For example, splitting at position `k=2`:\n",
    "- Left: `[\"R\", \"B\"]`\n",
    "- Right: `[\"B\", \"R\", \"R\"]`\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. For `items = [\"R\", \"B\", \"B\", \"R\", \"R\"]`, print the left and right parts for **every possible split position** `k = 1, 2, 3, 4`.\n",
    "   - (Why not `k=0` or `k=5`? What would those give?)\n",
    "\n",
    "2. For each split position, compute `total_impurity(left, right)`. Print all values.\n",
    "\n",
    "3. Which split position gives the **minimum** total impurity? \n",
    "   - What are the left and right groups at that position?\n",
    "   - Does that split make intuitive sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "items = [\"R\", \"B\", \"B\", \"R\", \"R\"]\n",
    "\n",
    "print(f\"{'k':<5} {'left':<25} {'right':<25} {'total impurity':>15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for k in range(1, len(items)):\n",
    "    left = items[:k]\n",
    "    right = items[k:]\n",
    "    imp = total_impurity(left, right)\n",
    "    print(f\"{k:<5} {str(left):<25} {str(right):<25} {imp:>15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-20",
   "metadata": {},
   "source": [
    "## Exercise 3.2 — The Best Split Function\n",
    "\n",
    "Now automate it: write a function `find_best_split_position(items)` that:\n",
    "- Tries every possible split position `k = 1` to `len(items) - 1`\n",
    "- Computes `total_impurity` at each position\n",
    "- Returns the position `k` that gives the **minimum** total impurity\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Implement `find_best_split_position(items)`. It should return the best `k` and the minimum total impurity.\n",
    "\n",
    "2. Test it on these lists:\n",
    "   ```python\n",
    "   [\"R\", \"B\", \"B\", \"R\", \"R\"]\n",
    "   [\"R\", \"R\", \"R\", \"B\", \"B\", \"B\"]\n",
    "   [\"B\", \"R\", \"B\", \"R\", \"B\", \"R\"]\n",
    "   [\"R\", \"R\", \"R\", \"R\", \"B\"]\n",
    "   ```\n",
    "\n",
    "3. For `[\"R\", \"R\", \"R\", \"B\", \"B\", \"B\"]`, the answer should be obvious from visual inspection. Does your function agree?\n",
    "\n",
    "4. For `[\"B\", \"R\", \"B\", \"R\", \"B\", \"R\"]` (perfectly alternating), what split position does it find? Are there multiple \"tied\" positions? How does your function handle ties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def find_best_split_position(items):\n",
    "    \"\"\"\n",
    "    Finds the split position k that minimises total_impurity(items[:k], items[k:]).\n",
    "    Returns (best_k, min_impurity).\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "# Test\n",
    "test_lists = [\n",
    "    [\"R\", \"B\", \"B\", \"R\", \"R\"],\n",
    "    [\"R\", \"R\", \"R\", \"B\", \"B\", \"B\"],\n",
    "    [\"B\", \"R\", \"B\", \"R\", \"B\", \"R\"],\n",
    "    [\"R\", \"R\", \"R\", \"R\", \"B\"],\n",
    "]\n",
    "\n",
    "for lst in test_lists:\n",
    "    best_k, min_imp = find_best_split_position(lst)\n",
    "    print(f\"List: {lst}\")\n",
    "    print(f\"  Best k={best_k}: left={lst[:best_k]}, right={lst[best_k:]}\")\n",
    "    print(f\"  Min impurity: {min_imp:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-22",
   "metadata": {},
   "source": [
    "## Exercise 3.3 — Visualise the Split Scores\n",
    "\n",
    "Use the plotting helper below to visualise how total impurity changes at each split position.\n",
    "\n",
    "```python\n",
    "def plot_split_scores(items, title=None):\n",
    "    \"\"\"\n",
    "    Plots total_impurity vs split position k for a given list.\n",
    "    Marks the best (minimum impurity) position.\n",
    "    \"\"\"\n",
    "    ks = list(range(1, len(items)))\n",
    "    scores = [total_impurity(items[:k], items[k:]) for k in ks]\n",
    "    best_k = ks[scores.index(min(scores))]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(ks, scores, 'b-o')\n",
    "    plt.axvline(x=best_k, color='red', linestyle='--', label=f'best k={best_k}')\n",
    "    plt.xlabel('Split position k')\n",
    "    plt.ylabel('Total impurity')\n",
    "    plt.title(title or f'Split scores for {items}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Run `plot_split_scores` on all four test lists from Exercise 3.2.\n",
    "2. For `[\"R\", \"R\", \"R\", \"B\", \"B\", \"B\"]`: is the minimum sharp or flat? Why?\n",
    "3. For `[\"B\", \"R\", \"B\", \"R\", \"B\", \"R\"]`: what does the plot look like? Is there a clear winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HELPER — run this cell as-is\n",
    "def plot_split_scores(items, title=None):\n",
    "    ks = list(range(1, len(items)))\n",
    "    scores = [total_impurity(items[:k], items[k:]) for k in ks]\n",
    "    best_k = ks[scores.index(min(scores))]\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(ks, scores, 'b-o')\n",
    "    plt.axvline(x=best_k, color='red', linestyle='--', label=f'best k={best_k}')\n",
    "    plt.xlabel('Split position k')\n",
    "    plt.ylabel('Total impurity')\n",
    "    plt.title(title or f'Split scores for {items}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — plot all four lists\n",
    "for lst in test_lists:\n",
    "    plot_split_scores(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 4: Splitting Real Data — Height & Gender\n",
    "\n",
    "## Exercise 4.1 — Meet the Dataset\n",
    "\n",
    "You are given a dataset of students in a class. Each student has a **height** (in cm) and a **gender** (\"M\" or \"F\").\n",
    "\n",
    "Run the cell below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET — run this cell as-is\n",
    "random.seed(42)\n",
    "\n",
    "heights = [158, 162, 165, 167, 168, 170, 171, 172, 174, 175,\n",
    "           176, 178, 179, 180, 181, 182, 183, 185, 187, 190]\n",
    "genders = [\"F\",  \"F\",  \"F\",  \"F\",  \"M\",  \"F\",  \"M\",  \"M\",  \"F\",  \"M\",\n",
    "           \"M\",  \"M\",  \"M\",  \"M\",  \"F\",  \"M\",  \"M\",  \"M\",  \"M\",  \"M\"]\n",
    "\n",
    "print(\"Height  Gender\")\n",
    "print(\"-\" * 16)\n",
    "for h, g in zip(heights, genders):\n",
    "    print(f\"{h:<8} {g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-27",
   "metadata": {},
   "source": [
    "**Before coding, answer these questions:**\n",
    "\n",
    "1. Just by looking at the data, at roughly what height does gender start being predominantly Male?\n",
    "2. If you had to draw a single horizontal line through the data to separate M from F as cleanly as possible, where would you draw it?\n",
    "3. Is a perfect separation possible? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-28",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-29",
   "metadata": {},
   "source": [
    "## Exercise 4.2 — Visualise the Data\n",
    "\n",
    "Run the plotting helper below to see the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HELPER — run this cell as-is\n",
    "def plot_height_gender(heights, genders, split_height=None, title=\"Height vs Gender\"):\n",
    "    \"\"\"\n",
    "    Scatter plot of height vs gender.\n",
    "    Optionally draws a vertical split line at split_height.\n",
    "    \"\"\"\n",
    "    colors = {\"M\": \"blue\", \"F\": \"red\"}\n",
    "    y_jitter = {\"M\": 1, \"F\": 0}\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for h, g in zip(heights, genders):\n",
    "        plt.scatter(h, y_jitter[g], color=colors[g], s=80, zorder=5)\n",
    "        plt.text(h, y_jitter[g] + 0.05, g, ha='center', fontsize=8)\n",
    "    if split_height is not None:\n",
    "        plt.axvline(x=split_height, color='green', linestyle='--', linewidth=2,\n",
    "                    label=f'split at {split_height}')\n",
    "        plt.legend()\n",
    "    plt.yticks([0, 1], [\"F\", \"M\"])\n",
    "    plt.xlabel(\"Height (cm)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plot_height_gender(heights, genders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-32",
   "metadata": {},
   "source": [
    "## Exercise 4.3 — Split by Height Threshold\n",
    "\n",
    "Now the key idea: instead of splitting at a *position* in a list, we split at a **threshold value** in a feature.\n",
    "\n",
    "For a given threshold `t`:\n",
    "- **Left group:** all rows where `height <= t`\n",
    "- **Right group:** all rows where `height > t`\n",
    "\n",
    "We compute the genders in each group, then calculate `total_impurity`.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Write a function `split_by_threshold(heights, genders, t)` that:\n",
    "   - Splits the data at threshold `t`\n",
    "   - Returns `(left_genders, right_genders)` where each is a list of gender labels\n",
    "\n",
    "2. Test it: `split_by_threshold(heights, genders, 172)` should return:\n",
    "   - left: genders of everyone with height ≤ 172\n",
    "   - right: genders of everyone with height > 172\n",
    "\n",
    "3. For the thresholds below, compute and print `total_impurity(left, right)`. Notice the pattern.\n",
    "\n",
    "   ```\n",
    "   t = 160, 165, 170, 172, 175, 178, 182, 185, 188\n",
    "   ```\n",
    "\n",
    "4. Which threshold gives the lowest total impurity? Verify visually using `plot_height_gender` with `split_height=t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def split_by_threshold(heights, genders, t):\n",
    "    \"\"\"\n",
    "    Splits the dataset at threshold t on height.\n",
    "    Returns (left_genders, right_genders) where:\n",
    "      left_genders  = genders where height <= t\n",
    "      right_genders = genders where height > t\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "# Test manually\n",
    "left, right = split_by_threshold(heights, genders, 172)\n",
    "print(\"Left (height <= 172):\", left)\n",
    "print(\"Right (height > 172):\", right)\n",
    "print(\"Total impurity:\", total_impurity(left, right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple thresholds\n",
    "thresholds = [160, 165, 170, 172, 175, 178, 182, 185, 188]\n",
    "\n",
    "print(f\"{'Threshold':<12} {'Left size':<12} {'Right size':<12} {'Total impurity':>15}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for t in thresholds:\n",
    "    left, right = split_by_threshold(heights, genders, t)\n",
    "    imp = total_impurity(left, right)\n",
    "    print(f\"{t:<12} {len(left):<12} {len(right):<12} {imp:>15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-35",
   "metadata": {},
   "source": [
    "## Exercise 4.4 — Find the Best Threshold Automatically\n",
    "\n",
    "Instead of manually trying thresholds, automate it.\n",
    "\n",
    "**Key insight:** You only need to try thresholds at the **unique values in your data** (or midpoints between consecutive values). Why? Because splitting at 173.5 vs 174 makes no difference if there's no data point between them.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Write `find_best_threshold(heights, genders)` that:\n",
    "   - Tries every unique height value as a threshold\n",
    "   - Computes `total_impurity` for each\n",
    "   - Returns the threshold with minimum total impurity, and that minimum impurity value\n",
    "\n",
    "2. Run it and print the result. Does it match your manual inspection?\n",
    "\n",
    "3. Visualise the best threshold using `plot_height_gender(heights, genders, split_height=best_t)`.\n",
    "\n",
    "4. **Reflection:** What are the genders in the left and right groups at the best threshold? Is the split clean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def find_best_threshold(heights, genders):\n",
    "    \"\"\"\n",
    "    Finds the height threshold that minimises total_impurity.\n",
    "    Returns (best_threshold, min_impurity).\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "best_t, best_imp = find_best_threshold(heights, genders)\n",
    "print(f\"Best threshold: height <= {best_t}\")\n",
    "print(f\"Minimum total impurity: {best_imp:.4f}\")\n",
    "\n",
    "left, right = split_by_threshold(heights, genders, best_t)\n",
    "print(f\"Left group:  {left}\")\n",
    "print(f\"Right group: {right}\")\n",
    "\n",
    "plot_height_gender(heights, genders, split_height=best_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-37",
   "metadata": {},
   "source": [
    "## Exercise 4.5 — Plot Impurity vs Threshold\n",
    "\n",
    "Use the plotting helper below to visualise how impurity changes as the threshold varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HELPER — run this cell as-is\n",
    "def plot_threshold_scores(heights, genders, title=\"Impurity vs Threshold\"):\n",
    "    \"\"\"\n",
    "    Plots total impurity for each unique height threshold.\n",
    "    \"\"\"\n",
    "    unique_heights = sorted(set(heights))\n",
    "    scores = []\n",
    "    for t in unique_heights:\n",
    "        left = [g for h, g in zip(heights, genders) if h <= t]\n",
    "        right = [g for h, g in zip(heights, genders) if h > t]\n",
    "        if left and right:\n",
    "            scores.append((t, total_impurity(left, right)))\n",
    "\n",
    "    ts, imps = zip(*scores)\n",
    "    best_t = ts[imps.index(min(imps))]\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.plot(ts, imps, 'b-o')\n",
    "    plt.axvline(x=best_t, color='red', linestyle='--', label=f'best t={best_t}')\n",
    "    plt.xlabel('Threshold (height cm)')\n",
    "    plt.ylabel('Total impurity')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — run the plot\n",
    "plot_threshold_scores(heights, genders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 5: A Decision Node — The Job Offer\n",
    "\n",
    "## Exercise 5.1 — What Is a Decision Tree Node?\n",
    "\n",
    "Before we build a full tree from data, let's understand the structure of a decision tree by **constructing one by hand**.\n",
    "\n",
    "A decision tree is made of **nodes**. There are two kinds:\n",
    "\n",
    "- **Boundary node:** Has a rule — \"if feature X ≤ value, go left; else go right.\" Has two children.\n",
    "- **Leaf node:** Has a final answer — just `True` (YES) or `False` (NO). No children.\n",
    "\n",
    "Here is a tree for deciding whether to accept a job offer:\n",
    "\n",
    "```\n",
    "Is salary > 1000?\n",
    "├── NO  → Reject the offer\n",
    "└── YES → Is distance <= 40?\n",
    "           ├── YES → Accept the offer\n",
    "           └── NO  → Reject the offer\n",
    "```\n",
    "\n",
    "**Before coding, answer these questions:**\n",
    "\n",
    "1. If a job pays 800 and is 20km away — what does the tree say?\n",
    "2. If a job pays 1200 and is 30km away — what does the tree say?\n",
    "3. If a job pays 1500 and is 60km away — what does the tree say?\n",
    "4. If a job pays 1000 exactly — which branch do you take? (Careful: the rule is `salary > 1000`.)\n",
    "\n",
    "Write your answers below before coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-41",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "\n",
    "1. salary=800, distance=20 → ...\n",
    "2. salary=1200, distance=30 → ...\n",
    "3. salary=1500, distance=60 → ...\n",
    "4. salary=1000, distance=any → ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-42",
   "metadata": {},
   "source": [
    "## Exercise 5.2 — Build the `DecisionTreeNode` Class\n",
    "\n",
    "Design a class `DecisionTreeNode` that can be either a **boundary node** or a **leaf node**.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- A **leaf node** stores a boolean `decision` (`True` = YES, `False` = NO).\n",
    "- A **boundary node** stores:\n",
    "  - `boundary` — the feature name (a string, e.g. `\"salary\"`)\n",
    "  - `boundary_value` — the threshold (a number)\n",
    "  - `left` — the child node for when `feature <= boundary_value`\n",
    "  - `right` — the child node for when `feature > boundary_value`\n",
    "- A method `check(features)` that:\n",
    "  - Takes a dict like `{\"salary\": 1200, \"distance\": 30}`\n",
    "  - Traverses the tree\n",
    "  - Returns the leaf's boolean `decision`\n",
    "\n",
    "**Also create two helper functions:**\n",
    "- `YES()` — returns a leaf node with decision `True`\n",
    "- `NO()` — returns a leaf node with decision `False`\n",
    "\n",
    "**Hint for the class structure:**\n",
    "```python\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, ...):\n",
    "        # your attributes here\n",
    "        pass\n",
    "\n",
    "    def check(self, features):\n",
    "        # if leaf: return decision\n",
    "        # if boundary: go left or right depending on features[self.boundary]\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Implement `DecisionTreeNode`, `YES()`, and `NO()`.\n",
    "2. Build the job offer tree manually:\n",
    "   ```\n",
    "   Is salary <= 1000? → NO()\n",
    "   Else: Is distance <= 40? → YES() else NO()\n",
    "   ```\n",
    "3. Test it against your answers from Exercise 5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, decision=None, boundary=None, boundary_value=None, left=None, right=None):\n",
    "        \"\"\"\n",
    "        A node in a decision tree.\n",
    "        \n",
    "        If decision is not None: this is a leaf node.\n",
    "        Otherwise: this is a boundary node with boundary, boundary_value, left, right.\n",
    "        \"\"\"\n",
    "        pass  # replace this\n",
    "\n",
    "    def check(self, features):\n",
    "        \"\"\"\n",
    "        Traverses the tree and returns the leaf's boolean decision.\n",
    "        features: dict of {feature_name: value}\n",
    "        Rule: go LEFT if features[boundary] <= boundary_value, else go RIGHT.\n",
    "        \"\"\"\n",
    "        pass  # replace this\n",
    "\n",
    "\n",
    "def YES():\n",
    "    \"\"\"Returns a leaf node that decides True (accept).\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def NO():\n",
    "    \"\"\"Returns a leaf node that decides False (reject).\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the job offer tree\n",
    "# Tree:\n",
    "#   salary <= 1000 → NO\n",
    "#   salary > 1000:\n",
    "#       distance <= 40 → YES\n",
    "#       distance > 40  → NO\n",
    "\n",
    "job_tree = DecisionTreeNode(\n",
    "    boundary=\"salary\",\n",
    "    boundary_value=1000,\n",
    "    left=NO(),\n",
    "    right=DecisionTreeNode(\n",
    "        boundary=\"distance\",\n",
    "        boundary_value=40,\n",
    "        left=YES(),\n",
    "        right=NO()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Test the four cases from Exercise 5.1\n",
    "test_jobs = [\n",
    "    {\"salary\": 800,  \"distance\": 20, \"expected\": False},\n",
    "    {\"salary\": 1200, \"distance\": 30, \"expected\": True},\n",
    "    {\"salary\": 1500, \"distance\": 60, \"expected\": False},\n",
    "    {\"salary\": 1000, \"distance\": 15, \"expected\": False},\n",
    "]\n",
    "\n",
    "print(f\"{'Salary':<10} {'Distance':<12} {'Result':<10} {'Expected':<10} {'Match'}\")\n",
    "print(\"-\" * 55)\n",
    "for job in test_jobs:\n",
    "    result = job_tree.check(job)\n",
    "    match = \"✓\" if result == job[\"expected\"] else \"✗\"\n",
    "    print(f\"{job['salary']:<10} {job['distance']:<12} {str(result):<10} {str(job['expected']):<10} {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-45",
   "metadata": {},
   "source": [
    "## Exercise 5.3 — A Bigger Tree\n",
    "\n",
    "Now build a more complex tree by hand. This tree has 3 levels:\n",
    "\n",
    "```\n",
    "Is salary <= 1000?\n",
    "├── YES → NO (reject)\n",
    "└── NO (salary > 1000):\n",
    "    Is distance <= 40?\n",
    "    ├── YES (close enough):\n",
    "    │   Is coffee == 1?         ← 1 means \"office has free coffee\"\n",
    "    │   ├── YES → YES (accept)\n",
    "    │   └── NO  → NO (reject)\n",
    "    └── NO (too far) → NO (reject)\n",
    "```\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Build this tree using `DecisionTreeNode`, `YES()`, and `NO()`.\n",
    "2. Test with these job offers:\n",
    "\n",
    "| salary | distance | coffee | Expected |\n",
    "|--------|----------|--------|----------|\n",
    "| 1200   | 30       | 1      | YES      |\n",
    "| 1200   | 30       | 0      | NO       |\n",
    "| 1200   | 60       | 1      | NO       |\n",
    "| 900    | 10       | 1      | NO       |\n",
    "\n",
    "3. Extend the tree by adding one more rule of your own. Document it in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — build the 3-level tree\n",
    "job_tree_v2 = None  # replace with your tree\n",
    "\n",
    "# Test cases\n",
    "test_v2 = [\n",
    "    {\"salary\": 1200, \"distance\": 30, \"coffee\": 1, \"expected\": True},\n",
    "    {\"salary\": 1200, \"distance\": 30, \"coffee\": 0, \"expected\": False},\n",
    "    {\"salary\": 1200, \"distance\": 60, \"coffee\": 1, \"expected\": False},\n",
    "    {\"salary\": 900,  \"distance\": 10, \"coffee\": 1, \"expected\": False},\n",
    "]\n",
    "\n",
    "for job in test_v2:\n",
    "    result = job_tree_v2.check(job)\n",
    "    match = \"✓\" if result == job[\"expected\"] else \"✗\"\n",
    "    print(f\"salary={job['salary']}, distance={job['distance']}, coffee={job['coffee']}  →  {result}  {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-47",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 6: Multiple Features — Finding the Best Split\n",
    "\n",
    "## Exercise 6.1 — Add a Second Feature: Weight\n",
    "\n",
    "Now the dataset has **two features**: height and weight. We want to find which feature and which threshold gives the best split.\n",
    "\n",
    "Run the cell below to load the extended dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTENDED DATASET — run this cell as-is\n",
    "data = [\n",
    "    {\"height\": 158, \"weight\": 52, \"gender\": \"F\"},\n",
    "    {\"height\": 162, \"weight\": 55, \"gender\": \"F\"},\n",
    "    {\"height\": 165, \"weight\": 58, \"gender\": \"F\"},\n",
    "    {\"height\": 167, \"weight\": 61, \"gender\": \"F\"},\n",
    "    {\"height\": 168, \"weight\": 70, \"gender\": \"M\"},\n",
    "    {\"height\": 170, \"weight\": 60, \"gender\": \"F\"},\n",
    "    {\"height\": 171, \"weight\": 73, \"gender\": \"M\"},\n",
    "    {\"height\": 172, \"weight\": 75, \"gender\": \"M\"},\n",
    "    {\"height\": 174, \"weight\": 63, \"gender\": \"F\"},\n",
    "    {\"height\": 175, \"weight\": 78, \"gender\": \"M\"},\n",
    "    {\"height\": 176, \"weight\": 80, \"gender\": \"M\"},\n",
    "    {\"height\": 178, \"weight\": 82, \"gender\": \"M\"},\n",
    "    {\"height\": 179, \"weight\": 84, \"gender\": \"M\"},\n",
    "    {\"height\": 180, \"weight\": 85, \"gender\": \"M\"},\n",
    "    {\"height\": 181, \"weight\": 66, \"gender\": \"F\"},\n",
    "    {\"height\": 182, \"weight\": 88, \"gender\": \"M\"},\n",
    "    {\"height\": 183, \"weight\": 90, \"gender\": \"M\"},\n",
    "    {\"height\": 185, \"weight\": 92, \"gender\": \"M\"},\n",
    "    {\"height\": 187, \"weight\": 95, \"gender\": \"M\"},\n",
    "    {\"height\": 190, \"weight\": 98, \"gender\": \"M\"},\n",
    "]\n",
    "\n",
    "print(f\"{'Height':<8} {'Weight':<8} {'Gender'}\")\n",
    "print(\"-\" * 24)\n",
    "for row in data:\n",
    "    print(f\"{row['height']:<8} {row['weight']:<8} {row['gender']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-49",
   "metadata": {},
   "source": [
    "## Exercise 6.2 — Find the Best Feature and Threshold\n",
    "\n",
    "**The question:** Should we split on **height** or **weight**, and at what value?\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Write a function `find_decision_boundary(data, features, label)` that:\n",
    "- Takes a list of dicts (`data`), a list of feature names to consider (`features`), and the label column name (`label`)\n",
    "- For **each feature** in `features`:\n",
    "  - Tries every unique value of that feature as a threshold\n",
    "  - Computes `total_impurity` for that split\n",
    "- Returns the **best feature name**, the **best threshold**, and the **minimum impurity**\n",
    "\n",
    "**Step-by-step hints:**\n",
    "1. Extract all unique values for a feature: `sorted(set(row[feature] for row in data))`\n",
    "2. For each threshold `t`, the left group is `[row[label] for row in data if row[feature] <= t]`\n",
    "3. Track the best (feature, threshold, impurity) triple as you loop\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Implement `find_decision_boundary`.\n",
    "2. Run it on the dataset with `features=[\"height\", \"weight\"]` and `label=\"gender\"`.\n",
    "3. Print the result. Which feature won? At what threshold?\n",
    "4. Does this match what you expected from looking at the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def find_decision_boundary(data, features, label):\n",
    "    \"\"\"\n",
    "    Finds the best (feature, threshold) split across all given features.\n",
    "    Returns (best_feature, best_threshold, min_impurity).\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "best_feat, best_thresh, best_imp = find_decision_boundary(data, [\"height\", \"weight\"], \"gender\")\n",
    "print(f\"Best split: {best_feat} <= {best_thresh}\")\n",
    "print(f\"Minimum total impurity: {best_imp:.4f}\")\n",
    "\n",
    "# What are the two groups?\n",
    "left_group = [row[\"gender\"] for row in data if row[best_feat] <= best_thresh]\n",
    "right_group = [row[\"gender\"] for row in data if row[best_feat] > best_thresh]\n",
    "print(f\"Left  ({best_feat} <= {best_thresh}): {left_group}\")\n",
    "print(f\"Right ({best_feat} >  {best_thresh}): {right_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-51",
   "metadata": {},
   "source": [
    "## Exercise 6.3 — Visualise Both Features\n",
    "\n",
    "Use the helper below to visualise both the height split and the weight split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HELPER — run this cell as-is\n",
    "def plot_feature_split(data, feature, label, split_value=None, title=None):\n",
    "    \"\"\"\n",
    "    Plots a feature vs label. Optionally marks a split threshold.\n",
    "    \"\"\"\n",
    "    color_map = {\"M\": \"blue\", \"F\": \"red\"}\n",
    "    y_map = {\"M\": 1, \"F\": 0}\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    for row in data:\n",
    "        x = row[feature]\n",
    "        y = y_map[row[label]]\n",
    "        c = color_map[row[label]]\n",
    "        plt.scatter(x, y, color=c, s=80, zorder=5)\n",
    "        plt.text(x, y + 0.06, row[label], ha='center', fontsize=8)\n",
    "\n",
    "    if split_value is not None:\n",
    "        plt.axvline(x=split_value, color='green', linestyle='--', linewidth=2,\n",
    "                    label=f'split at {split_value}')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.yticks([0, 1], [\"F\", \"M\"])\n",
    "    plt.xlabel(feature)\n",
    "    plt.title(title or f\"{feature} vs {label}\")\n",
    "    plt.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — plot height split and weight split\n",
    "# Use find_decision_boundary first on each feature separately\n",
    "\n",
    "best_h, best_ht, imp_h = find_decision_boundary(data, [\"height\"], \"gender\")\n",
    "best_w, best_wt, imp_w = find_decision_boundary(data, [\"weight\"], \"gender\")\n",
    "\n",
    "print(f\"Best height split: height <= {best_ht}, impurity = {imp_h:.4f}\")\n",
    "print(f\"Best weight split: weight <= {best_wt}, impurity = {imp_w:.4f}\")\n",
    "\n",
    "plot_feature_split(data, \"height\", \"gender\", split_value=best_ht, title=f\"Height split at {best_ht} (impurity={imp_h:.3f})\")\n",
    "plot_feature_split(data, \"weight\", \"gender\", split_value=best_wt, title=f\"Weight split at {best_wt} (impurity={imp_w:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 7: Growing the Tree — Recursive Splitting\n",
    "\n",
    "## Exercise 7.1 — What Happens After the First Split?\n",
    "\n",
    "After the first split, you have two groups. Each group may still be impure (mixed). \n",
    "\n",
    "The idea: **repeat the splitting** on each group independently, until each group is pure (impurity = 1) or has only 1 element.\n",
    "\n",
    "**Before coding, trace through manually:**\n",
    "\n",
    "Using the height-only dataset from Part 4:\n",
    "```python\n",
    "heights = [158, 162, 165, 167, 168, 170, 171, 172, 174, 175,\n",
    "           176, 178, 179, 180, 181, 182, 183, 185, 187, 190]\n",
    "genders = [\"F\",  \"F\",  \"F\",  \"F\",  \"M\",  \"F\",  \"M\",  \"M\",  \"F\",  \"M\",\n",
    "           \"M\",  \"M\",  \"M\",  \"M\",  \"F\",  \"M\",  \"M\",  \"M\",  \"M\",  \"M\"]\n",
    "```\n",
    "\n",
    "1. What is the best first split threshold? (You found this in Part 4.)\n",
    "2. After splitting, what are the left and right groups?\n",
    "3. Is the left group pure? Is the right group pure?\n",
    "4. For the impure group(s), what is the best next split?\n",
    "5. Draw this out as a tree structure in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-55",
   "metadata": {},
   "source": [
    "**Your manual tree sketch:**\n",
    "\n",
    "```\n",
    "height <= ???\n",
    "├── Left: ???  (pure? yes/no)\n",
    "│   └── If not pure, split again at height <= ???\n",
    "│       ├── ...\n",
    "│       └── ...\n",
    "└── Right: ???  (pure? yes/no)\n",
    "    └── If not pure, split again at height <= ???\n",
    "        ├── ...\n",
    "        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-56",
   "metadata": {},
   "source": [
    "## Exercise 7.2 — Stopping Conditions\n",
    "\n",
    "Before writing the recursive function, think about **when to stop**.\n",
    "\n",
    "**When should we NOT split further?**\n",
    "\n",
    "1. The group has **only 1 element** — nothing to split.\n",
    "2. The group is **completely pure** — impurity = 1 (all same label). No need to split.\n",
    "3. **(Optional / harder):** All elements have the **same feature values** — we can't find a meaningful threshold.\n",
    "\n",
    "**When we stop, what do we return?**  \n",
    "A **leaf node** with the majority label in that group.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Write a helper `majority_label(labels)` that takes a list of labels (like `[\"M\", \"M\", \"F\", \"M\"]`) and returns the most common one.\n",
    "   - What if there's a tie? Decide and document your choice.\n",
    "\n",
    "2. Write a helper `is_pure(labels)` that returns `True` if all labels are the same.\n",
    "\n",
    "3. Test both helpers:\n",
    "   ```python\n",
    "   majority_label([\"M\", \"M\", \"F\", \"M\"])  # → \"M\"\n",
    "   majority_label([\"F\", \"M\"])            # → tie: your choice\n",
    "   is_pure([\"M\", \"M\", \"M\"])             # → True\n",
    "   is_pure([\"M\", \"M\", \"F\"])             # → False\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def majority_label(labels):\n",
    "    \"\"\"\n",
    "    Returns the most common label in the list.\n",
    "    Document your tie-breaking rule here.\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "def is_pure(labels):\n",
    "    \"\"\"\n",
    "    Returns True if all labels are the same.\n",
    "    \"\"\"\n",
    "    pass  # replace this\n",
    "\n",
    "\n",
    "# Tests\n",
    "print(majority_label([\"M\", \"M\", \"F\", \"M\"]))  # M\n",
    "print(majority_label([\"F\", \"M\"]))            # tie — what do you return?\n",
    "print(is_pure([\"M\", \"M\", \"M\"]))             # True\n",
    "print(is_pure([\"M\", \"M\", \"F\"]))             # False\n",
    "print(is_pure([]))                          # edge case — what do you return?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-58",
   "metadata": {},
   "source": [
    "## Exercise 7.3 — Build the Tree Recursively\n",
    "\n",
    "Now write `build_tree(data, features, label)` that:\n",
    "\n",
    "1. **Base case:** If `data` is empty, or has 1 element, or is pure — return a `DecisionTreeNode` leaf with the majority label.\n",
    "2. **Recursive case:**\n",
    "   - Find the best feature and threshold using `find_decision_boundary`.\n",
    "   - Split `data` into `left_data` and `right_data`.\n",
    "   - Recursively call `build_tree` on each.\n",
    "   - Return a `DecisionTreeNode` boundary node with the two subtrees.\n",
    "\n",
    "**Important:** The leaf node now stores a **label string** (like `\"M\"` or `\"F\"`), not just `True`/`False`.\n",
    "You may need to adapt your `DecisionTreeNode` slightly, or use a convention like:\n",
    "- `decision = \"M\"` means this leaf predicts Male.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Implement `build_tree(data, features, label)`.\n",
    "2. Run it on the height+weight dataset from Part 6.\n",
    "3. Write a helper `print_tree(node, depth=0)` that prints the tree in an indented format.\n",
    "\n",
    "**Hint for `print_tree`:**\n",
    "```\n",
    "[height <= 175]\n",
    "  LEFT:\n",
    "    [weight <= 63]\n",
    "      LEFT:  LEAF → F\n",
    "      RIGHT: LEAF → M\n",
    "  RIGHT:\n",
    "    LEAF → M\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def build_tree(data, features, label):\n",
    "    \"\"\"\n",
    "    Recursively builds a decision tree.\n",
    "    \n",
    "    data     : list of dicts\n",
    "    features : list of feature names to split on\n",
    "    label    : the target column name\n",
    "    \n",
    "    Returns a DecisionTreeNode (either leaf or boundary).\n",
    "    \"\"\"\n",
    "    labels = [row[label] for row in data]\n",
    "\n",
    "    # Base case 1: empty data\n",
    "    if len(data) == 0:\n",
    "        pass  # return a leaf — but with what label?\n",
    "\n",
    "    # Base case 2: pure or single element\n",
    "    if is_pure(labels) or len(data) == 1:\n",
    "        pass  # return a leaf\n",
    "\n",
    "    # Recursive case\n",
    "    best_feat, best_thresh, best_imp = find_decision_boundary(data, features, label)\n",
    "\n",
    "    left_data  = [row for row in data if row[best_feat] <= best_thresh]\n",
    "    right_data = [row for row in data if row[best_feat] >  best_thresh]\n",
    "\n",
    "    # Safety: if the split doesn't separate anything, stop\n",
    "    if len(left_data) == 0 or len(right_data) == 0:\n",
    "        pass  # return a leaf\n",
    "\n",
    "    left_tree  = build_tree(left_data,  features, label)\n",
    "    right_tree = build_tree(right_data, features, label)\n",
    "\n",
    "    return DecisionTreeNode(\n",
    "        boundary=best_feat,\n",
    "        boundary_value=best_thresh,\n",
    "        left=left_tree,\n",
    "        right=right_tree\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to print the tree\n",
    "def print_tree(node, depth=0, label=\"ROOT\"):\n",
    "    \"\"\"\n",
    "    Prints the tree in an indented format.\n",
    "    Implement this yourself!\n",
    "    \"\"\"\n",
    "    indent = \"  \" * depth\n",
    "    if node.decision is not None:  # leaf node\n",
    "        print(f\"{indent}[{label}] LEAF → {node.decision}\")\n",
    "    else:  # boundary node\n",
    "        print(f\"{indent}[{label}] {node.boundary} <= {node.boundary_value}?\")\n",
    "        print_tree(node.left,  depth + 1, label=\"YES (left)\")\n",
    "        print_tree(node.right, depth + 1, label=\"NO (right)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and print the tree\n",
    "tree = build_tree(data, features=[\"height\", \"weight\"], label=\"gender\")\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-62",
   "metadata": {},
   "source": [
    "## Exercise 7.4 — Use the Tree to Predict\n",
    "\n",
    "Now use your built tree to predict the gender of new (unseen) individuals.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Use `tree.check(row)` to predict the gender for each row in the original `data`.\n",
    "2. Compare the prediction to the true label.\n",
    "3. Count how many predictions are correct. What is the **accuracy** (correct / total)?\n",
    "4. Which rows does the tree get wrong? Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "correct = 0\n",
    "print(f\"{'Height':<8} {'Weight':<8} {'True':<8} {'Predicted':<12} {'Match'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for row in data:\n",
    "    predicted = tree.check(row)\n",
    "    true_label = row[\"gender\"]\n",
    "    match = \"✓\" if predicted == true_label else \"✗\"\n",
    "    if predicted == true_label:\n",
    "        correct += 1\n",
    "    print(f\"{row['height']:<8} {row['weight']:<8} {true_label:<8} {str(predicted):<12} {match}\")\n",
    "\n",
    "print(f\"\\nAccuracy: {correct}/{len(data)} = {correct/len(data)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-64",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 8: The Full Decision Tree — `fit` and `predict`\n",
    "\n",
    "## Exercise 8.1 — The Interface\n",
    "\n",
    "Real ML libraries use a standard interface:\n",
    "- `fit(X, y)` — train the model on data `X` (features) and labels `y`\n",
    "- `predict(X)` — given new data, return predictions\n",
    "\n",
    "Here, `X` will be a list of dicts (one per sample), and `y` will be a list of labels.\n",
    "\n",
    "**Before coding**, think about these questions:\n",
    "\n",
    "1. In `fit(X, y)`: how do you know which features to try splitting on?\n",
    "2. In `predict(X)`: `X` is a list of rows — so `predict` should return a **list** of predictions.\n",
    "3. What should a leaf return when `check` is called on it?\n",
    "   - Currently it stores the majority label as a string.\n",
    "   - Should `predict` return raw labels, or something else?\n",
    "\n",
    "Write your answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-65",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "\n",
    "1. Features to split on: ...\n",
    "2. `predict` returns: ...\n",
    "3. Leaf behaviour: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-66",
   "metadata": {},
   "source": [
    "## Exercise 8.2 — Implement `SimpleDecisionTree`\n",
    "\n",
    "Now wrap everything into a clean class.\n",
    "\n",
    "```python\n",
    "class SimpleDecisionTree:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X : list of dicts (each dict is one row of features)\n",
    "        y : list of labels (strings or booleans)\n",
    "        \n",
    "        Builds the decision tree and stores it in self.root.\n",
    "        Also stores the feature names in self.features.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X : list of dicts\n",
    "        Returns a list of predicted labels, one per row.\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Implement `SimpleDecisionTree` using `build_tree` inside `fit`.\n",
    "2. Separate `X` and `y` before fitting. Combine them inside `fit` to pass to `build_tree`.\n",
    "3. Test it on the height+weight dataset:\n",
    "   ```python\n",
    "   X = [{\"height\": row[\"height\"], \"weight\": row[\"weight\"]} for row in data]\n",
    "   y = [row[\"gender\"] for row in data]\n",
    "   \n",
    "   clf = SimpleDecisionTree()\n",
    "   clf.fit(X, y)\n",
    "   predictions = clf.predict(X)\n",
    "   ```\n",
    "4. Compute accuracy.\n",
    "5. Now predict on some **new unseen data**:\n",
    "   ```python\n",
    "   new_people = [\n",
    "       {\"height\": 163, \"weight\": 54},   # your guess: F or M?\n",
    "       {\"height\": 185, \"weight\": 91},   # your guess: F or M?\n",
    "       {\"height\": 172, \"weight\": 65},   # your guess: F or M?\n",
    "   ]\n",
    "   ```\n",
    "   Does the tree's prediction match your intuition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class SimpleDecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        self.features = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X : list of dicts (features)\n",
    "        y : list of labels\n",
    "        \"\"\"\n",
    "        pass  # replace this\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X : list of dicts\n",
    "        Returns a list of predicted labels.\n",
    "        \"\"\"\n",
    "        pass  # replace this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the full pipeline\n",
    "X = [{\"height\": row[\"height\"], \"weight\": row[\"weight\"]} for row in data]\n",
    "y = [row[\"gender\"] for row in data]\n",
    "\n",
    "clf = SimpleDecisionTree()\n",
    "clf.fit(X, y)\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "# Accuracy\n",
    "correct = sum(p == t for p, t in zip(predictions, y))\n",
    "print(f\"Training accuracy: {correct}/{len(y)} = {correct/len(y)*100:.1f}%\")\n",
    "\n",
    "# Predict on new data\n",
    "new_people = [\n",
    "    {\"height\": 163, \"weight\": 54},\n",
    "    {\"height\": 185, \"weight\": 91},\n",
    "    {\"height\": 172, \"weight\": 65},\n",
    "]\n",
    "new_preds = clf.predict(new_people)\n",
    "print(\"\\nNew predictions:\")\n",
    "for person, pred in zip(new_people, new_preds):\n",
    "    print(f\"  height={person['height']}, weight={person['weight']}  →  {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-69",
   "metadata": {},
   "source": [
    "## Exercise 8.3 — Print the Learned Tree\n",
    "\n",
    "Use your `print_tree` function to display the tree learned by `SimpleDecisionTree`.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Call `print_tree(clf.root)`.\n",
    "2. How deep is the tree? Count the levels.\n",
    "3. Does the tree make intuitive sense? Are the splits reasonable?\n",
    "4. What would happen if you trained on a dataset with **more noise** — would the tree be deeper or shallower? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "print_tree(clf.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-71",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 9: Bonus Challenges\n",
    "\n",
    "If you've made it here, you've built a decision tree from scratch — impurity formula, split search, recursive tree growth, and a full ML-style class. Here are open-ended extensions.\n",
    "\n",
    "---\n",
    "\n",
    "## Challenge A — Max Depth\n",
    "\n",
    "Your tree keeps splitting until each leaf is pure. This can lead to **overfitting** — the tree memorises the training data but won't generalise to new data.\n",
    "\n",
    "Add a `max_depth` parameter to `SimpleDecisionTree` (and `build_tree`):\n",
    "- If the current depth equals `max_depth`, stop and return a leaf regardless of purity.\n",
    "\n",
    "1. Try `max_depth=1`, `2`, `3`. How does accuracy on the training set change?\n",
    "2. What does the tree look like with `max_depth=1`? This is called a **decision stump**.\n",
    "3. In general: deeper tree = higher training accuracy. Is that always better? Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge A — YOUR CODE\n",
    "# Modify build_tree and SimpleDecisionTree to support max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-73",
   "metadata": {},
   "source": [
    "## Challenge B — Min Samples to Split\n",
    "\n",
    "Another way to prevent overfitting: don't split a group if it has fewer than `min_samples` rows.\n",
    "\n",
    "Add a `min_samples` parameter:\n",
    "- If `len(data) < min_samples`, return a leaf.\n",
    "\n",
    "Try `min_samples=1` (default, current behaviour) vs `min_samples=3` vs `min_samples=5`.\n",
    "How does the tree structure change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge B — YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-75",
   "metadata": {},
   "source": [
    "## Challenge C — A New Dataset\n",
    "\n",
    "Try your tree on the Iris dataset — a classic ML benchmark.\n",
    "\n",
    "```python\n",
    "# Load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to the format your tree expects\n",
    "feature_names = iris.feature_names  # 4 features\n",
    "X_iris = [dict(zip(feature_names, row)) for row in iris.data]\n",
    "y_iris = [iris.target_names[t] for t in iris.target]  # \"setosa\", \"versicolor\", \"virginica\"\n",
    "```\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Fit your `SimpleDecisionTree` on the Iris dataset.\n",
    "2. Compute training accuracy.\n",
    "3. Print the tree. How deep is it?\n",
    "4. Compare to `sklearn.tree.DecisionTreeClassifier`. Do they make the same splits?\n",
    "5. **Bonus:** Split into train/test sets (80/20) and measure test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge C — YOUR CODE\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "feature_names = iris.feature_names\n",
    "X_iris = [dict(zip(feature_names, row)) for row in iris.data]\n",
    "y_iris = [iris.target_names[t] for t in iris.target]\n",
    "\n",
    "clf_iris = SimpleDecisionTree()\n",
    "clf_iris.fit(X_iris, y_iris)\n",
    "\n",
    "preds = clf_iris.predict(X_iris)\n",
    "acc = sum(p == t for p, t in zip(preds, y_iris)) / len(y_iris)\n",
    "print(f\"Iris training accuracy: {acc*100:.1f}%\")\n",
    "\n",
    "print(\"\\nTree structure:\")\n",
    "print_tree(clf_iris.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-77",
   "metadata": {},
   "source": [
    "## Challenge D — What Is Gini Impurity?\n",
    "\n",
    "The impurity function you invented is based on $p(1-p)$. Look up **Gini impurity**, which is:\n",
    "\n",
    "$$\\text{Gini} = 1 - \\sum_k p_k^2$$\n",
    "\n",
    "where the sum is over all classes `k`, and $p_k$ is the fraction of class `k`.\n",
    "\n",
    "1. For two classes (R and B), write out the Gini formula in full.\n",
    "2. Is it the same as your formula, or different?\n",
    "3. Replace your `impurity` function with the Gini formula and re-run everything. Do the results change?\n",
    "4. Look up **Entropy** as another impurity measure. Try implementing that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dt-78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge D — YOUR CODE\n",
    "\n",
    "def gini_impurity(p, q):\n",
    "    \"\"\"\n",
    "    Gini impurity for two classes.\n",
    "    Formula: 1 - (p^2 + q^2)\n",
    "    Note: Gini=0 when pure, Gini=0.5 when maximally mixed.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def entropy_impurity(p, q):\n",
    "    \"\"\"\n",
    "    Entropy impurity for two classes.\n",
    "    Formula: -(p * log2(p) + q * log2(q))  [handle p=0 or q=0 as 0]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Plot all three impurity measures on the same graph\n",
    "ps = [i/100 for i in range(101)]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(ps, [impurity(p, 1-p) for p in ps], label='Your formula')\n",
    "plt.plot(ps, [gini_impurity(p, 1-p) for p in ps], label='Gini', linestyle='--')\n",
    "plt.plot(ps, [entropy_impurity(p, 1-p) for p in ps], label='Entropy', linestyle=':')\n",
    "plt.xlabel('p'); plt.ylabel('impurity'); plt.title('Comparing impurity measures')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-79",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection — What Did You Just Build?\n",
    "\n",
    "Take a moment to answer these questions in your own words.\n",
    "\n",
    "1. **What is impurity?** Why does it matter for decision trees?\n",
    "\n",
    "2. **What is a decision boundary?** How did you find the best one?\n",
    "\n",
    "3. **What is recursive splitting?** When does it stop?\n",
    "\n",
    "4. **What is overfitting?** How does a decision tree overfit, and how can you prevent it?\n",
    "\n",
    "5. **What does `fit` do?** What does `predict` do?\n",
    "\n",
    "6. **What would a Random Forest be?** (Think: what if you built many trees on random subsets of data and features, then took a vote?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-80",
   "metadata": {},
   "source": [
    "**Your answers:**\n",
    "\n",
    "1. Impurity is...\n",
    "\n",
    "2. A decision boundary is...\n",
    "\n",
    "3. Recursive splitting means...\n",
    "\n",
    "4. Overfitting means...\n",
    "\n",
    "5. `fit` does... `predict` does...\n",
    "\n",
    "6. A Random Forest would be..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dt-81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*You've just invented a decision tree classifier from scratch — impurity, split search, recursive tree growth, and a full ML interface. That's the real thing. sklearn's `DecisionTreeClassifier` works on exactly these principles.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
